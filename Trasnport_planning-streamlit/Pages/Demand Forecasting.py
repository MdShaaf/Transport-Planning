import pandas as pd
import streamlit as st
import duckdb
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import json
import os
import time
from prophet import Prophet
import pickle
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,root_mean_squared_error
from pmdarima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX
from meteostat import Point, Hourly
import holidays
from xgboost import XGBRegressor
import numpy as np

st.title("üöó Demand Forecasting")
@st.cache_data
def load_data():
    con = duckdb.connect(database=':memory:', read_only=False)
    path=r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\Sampled_Data\combined_sampled_data.parquet"
    df = con.execute(f"SELECT * FROM '{path}'").df()
    return df
data = load_data()

#filling null values
data['passenger_count'].fillna(0, inplace=True)
data['RatecodeID'].fillna(-1, inplace=True)
data['store_and_fwd_flag'].fillna('N', inplace=True)
data['congestion_surcharge'].fillna(0, inplace=True)
data['Airport_fee'].fillna(0, inplace=True)

data=data[data['total_amount']>0]
data=data[data['trip_distance']<=100]
data['Date']=data['tpep_pickup_datetime'].dt.date
data['Hour']=data['tpep_pickup_datetime'].dt.hour
data['Date']=pd.to_datetime(data['Date'])
data=data[(data['Date'].dt.year)==2025]

resampling = data.groupby(['Date','Hour']).size().reset_index()
resampling =resampling.rename(columns={0:'Trips'})
resampling['Date & Time']=(resampling['Date']+pd.to_timedelta(resampling['Hour'],unit='h'))
resampling['naive_forecast'] = resampling['Trips'].shift(24)
resampling.dropna(inplace=True)
january = resampling[resampling['Date'].dt.month==1]


st.subheader("1. Naive Forecasting Model")
st.markdown("""
A naive forecasting model is a simple time series forecasting method that uses the most recent observed value as the forecast for the next period. In this case, we are using the value from 24 hours ago (the same hour on the previous day) as the forecast for the current hour. This approach assumes that there is a daily pattern in the data, which is common in many time series datasets, especially those related to human activities such as transportation demand.
""")
fig0, ax0 = plt.subplots(figsize=(14,6))
fig0.patch.set_facecolor('black')
ax0.set_facecolor('black')

ax0.plot(
    january['Date & Time'],
    january['Trips'],
    label='Actual Trips',
    color='blue',
    linewidth=2
)
ax0.plot(
    january['Date & Time'],
    january['naive_forecast'],
    label='Naive Forecast',
    color='orange',
    linestyle='--',
    linewidth=2
)

# Labels & title
ax0.set_xlabel('Datetime', color='white',fontsize=15)
ax0.set_ylabel('Trips', color='white',fontsize=15)
ax0.set_title('Naive Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax0.tick_params(colors='white')

# Grid (optional but recommended)
ax0.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax0.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig0)
st.markdown("""
In the plot above, the blue line represents the actual number of trips recorded each hour in January 2025, while the orange line represents the forecasts generated by the naive model. As we can see, the naive forecast captures the general daily patterns in the data, but there are discrepancies between the actual trips and the forecasted values, especially during peak hours. This indicates that while the naive model is a good starting point, more sophisticated models may be needed to improve forecasting accuracy.
""")
st.markdown(
    "<h3 style='text-align: center;'>Performance Metrics</h3>",
    unsafe_allow_html=True
)

resampling['absolute_error'] = abs(resampling['Trips'] - resampling['naive_forecast'])
mae = mean_absolute_error(resampling['Trips'], resampling['naive_forecast'])
mse = mean_squared_error(resampling['Trips'], resampling['naive_forecast'])
rmse = root_mean_squared_error(resampling['Trips'], resampling['naive_forecast'])
# r2  = r2_score(resampling['Trips'], resampling['naive_forecast'])
col1, col2, col3 = st.columns(3)

col1.metric("MAE", f"{mae:.2f}")
col2.metric("MSE", f"{mse:.2f}")
col3.metric("RMSE", f"{rmse:.2f}")
# col4.metric("R2_Score",f"{r2:.2f}")

st.subheader("2. SARIMA Model")

st.markdown("""
SARIMA effectively models recurring travel demand patterns such as weekday‚Äìweekend variation and peak periods.
This allows the model to significantly reduce both average forecast error (MAE) and large deviations (RMSE), making it suitable for transport demand forecasting applications.
            """)
resampling_data_for_sarimax = resampling.set_index('Date & Time')

MODEL_PATH = r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\Trasnport_planning-streamlit\models/sarimax_model.pkl"
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
status = st.empty()

if os.path.exists(MODEL_PATH):
    status.success("‚úÖ Loading the saved model...")
    
    with open(MODEL_PATH, "rb") as f:
        sarimax_results = pickle.load(f)

    time.sleep(3)   # optional: let user see it
    status.empty()

else:
    status.info("‚è≥ Creating the SARIMA model (first run)...")

    # Based on AUTO-ARIMA Model
    order_best = (2, 0, 0)
    seasonal_order_best = (1, 0, 1, 24)

    sarimax_model = SARIMAX(
        resampling_data_for_sarimax['Trips'],
        order=order_best,
        seasonal_order=seasonal_order_best,
        enforce_stationarity=False,
        enforce_invertibility=False
    )

    sarimax_results = sarimax_model.fit(disp=False)

    with open(MODEL_PATH, "wb") as f:
        pickle.dump(sarimax_results, f)

    status.success("‚úÖ SARIMA model trained and saved")
    time.sleep(2)
    status.empty()

#assign a column to predicted values
resampling_data_for_sarimax['Fitted'] = sarimax_results.fittedvalues

#calculating the errors
resampling_data_for_sarimax['abs_error'] = abs(resampling_data_for_sarimax['Trips'] - resampling_data_for_sarimax['Fitted'])

sarimax_january = resampling_data_for_sarimax[resampling_data_for_sarimax.index.month==1]

fig, ax = plt.subplots(figsize=(14,6))

# Background colors
fig.patch.set_facecolor('black')
ax.set_facecolor('black')

# Plot lines (high contrast)
ax.plot(
    sarimax_january.index,
    sarimax_january['Trips'],
    label='Actual Trips',
    color='cyan',
    linewidth=2
)

ax.plot(
    sarimax_january.index,
    sarimax_january['Fitted'],
    label='SARIMA Fitted',
    color='orange',
    linestyle='--',
    linewidth=2
)

# Labels & title
ax.set_xlabel('Datetime', color='white',fontsize=15)
ax.set_ylabel('Trips', color='white',fontsize=15)
ax.set_title('SARIMA Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax.tick_params(colors='white')

# Grid (optional but recommended)
ax.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig)

#acuracy comaprision
mae_sarimax =mean_absolute_error(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])
mse_sarimax =mean_squared_error(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])
rmse_sarimax =root_mean_squared_error(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])
# r1_sarima = r2_score(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])

st.markdown(
    "<h3 style='text-align: center;'>Model Comparison: Baseline vs SARIMA</h3>",
    unsafe_allow_html=True
)

col1, col2, col3 = st.columns(3)

col1.metric(
    label="MAE",
    value=f"{mae_sarimax:.2f}",
    delta="51% lower than baseline"
)

col2.metric(
    label="MSE",
    value=f"{mse_sarimax:.2f}",
    delta="80% lower than baseline"
)

col3.metric(
    label="RMSE",
    value=f"{rmse_sarimax:.2f}",
    delta="56% lower than baseline"
)


####Prophet Model 

st.subheader("3. Prophet Model")

prophet_data = (resampling_data_for_sarimax.reset_index())
prophet_data = prophet_data[['Date & Time','Trips']]
prophet_data=prophet_data.rename(columns={'Date & Time':'ds','Trips':'y'})

prophet_model_path = r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\models\prophet_model.pkl"
os.makedirs(os.path.dirname(prophet_model_path), exist_ok=True)
status = st.empty()

if os.path.exists(prophet_model_path):
    status.success("‚úÖ Loading the saved model...")
    
    with open(prophet_model_path, "rb") as f:
        prophet_model = pickle.load(f)

    time.sleep(3)   # optional: let user see it
    status.empty()

else:
    status.info("‚è≥ Error:Prophet Model doesn't exists please create and run again!!)...")

    time.sleep(2)
    status.empty()

future = prophet_model.make_future_dataframe(periods=0,freq='H')
prophet_forecast = prophet_model.predict(future)
df_compare = resampling_data_for_sarimax.copy()
df_compare['prophet_fitted'] = prophet_forecast['yhat'].values
df_compare['sarimax_fitted'] = sarimax_results.fittedvalues

#Let's compare the results
data_comaparision = df_compare[df_compare['Date'].dt.month==1]

plt.figure(figsize=(12,8))
plt.plot(data_comaparision.index,data_comaparision['Trips'],color='red')
plt.plot(data_comaparision.index,data_comaparision['prophet_fitted'],color='orange')
plt.plot(data_comaparision.index,data_comaparision['sarimax_fitted'],color='blue')
plt.show()

fig1, ax1 = plt.subplots(figsize=(14,6))

# Background colors
fig1.patch.set_facecolor('black')
ax1.set_facecolor('black')

# Plot lines (high contrast)
ax1.plot(
    data_comaparision.index,
    data_comaparision['Trips'],
    label='Actual Trips',
    color='blue',
    linewidth=2
)

# ax1.plot(
#     data_comaparision.index,
#     data_comaparision['sarimax_fitted'],
#     label='SARIMAX Fitted',
#     color='orange',
#     linestyle='--',
#     linewidth=2
# )

ax1.plot(
    data_comaparision.index,
    data_comaparision['prophet_fitted'],
    label='Prophet Fitted',
    color='red',
    linestyle='--',
    linewidth=2
)
# Labels & title
ax1.set_xlabel('Datetime', color='white',fontsize=15)
ax1.set_ylabel('Trips', color='white',fontsize=15)
ax1.set_title('SARIMAX Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax1.tick_params(colors='white')

# Grid (optional but recommended)
ax1.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax1.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig1)

st.markdown(
    "<h3 style='text-align: center;'>Performance Metrics</h3>",
    unsafe_allow_html=True
)


mae_prophet = mean_absolute_error(df_compare['Trips'], df_compare['prophet_fitted'])
mse_prophet = mean_squared_error(df_compare['Trips'], df_compare['prophet_fitted'])
rmse_prophet = np.sqrt(mse_prophet)

col1, col2, col3 = st.columns(3)

col1.metric(
    label="MAE",
    value=f"{mae_prophet:.2f}"
)
col2.metric(
    label="MSE",
    value=f"{mse_prophet:.2f}"
)

col3.metric(
    label="RMSE",
    value=f"{rmse_prophet:.2f}"

)

st.markdown(
    "<h3 style='text-align: center;'>Model Comparison: Prophet vs SARIMA</h3>",
    unsafe_allow_html=True
)

st.markdown("""
**Conclusion:**  
SARIMA outperforms Prophet across all evaluation metrics, reducing average and peak forecasting errors by nearly half. 
This makes SARIMA more suitable for operational transport demand forecasting.
""")

#Let's build some lag Features to try if SARIMAX imporvess
#Fetching Weather Data for NYC
st.subheader("Why Add Exogenous Features?")
st.markdown("""
Exogenous features such as **weather conditions** (temperature, rainfall, wind speed) and **calendar effects** (holidays and festive windows) were added to capture external factors that may influence taxi demand.

Although SARIMAX can model trends and seasonality using historical demand alone, real-world travel patterns are often affected by **non-temporal factors** such as bad weather or public holidays.  
Including these variables allows the model to test whether such external signals provide additional predictive power.
""")
#To avoid streamlit load time the exogenous features where added in a separate file and loaded the resampled data directly
@st.cache_data
def load_exogenous_data():
    path=r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\Sampled_Data/sarimax_exogenous_Data_with_resample.csv"
    df = pd.read_csv(path)
    return df
data_exogenous = load_exogenous_data()
data_exogenous.reset_index(drop=True,inplace=True)
data_exogenous['tpep_pickup_datetime'] =pd.to_datetime(data_exogenous['tpep_pickup_datetime'])
month_1 = data_exogenous[data_exogenous['tpep_pickup_datetime'].dt.month==1]

fig2, ax2 = plt.subplots(figsize=(14,6))

# Background colors
# Plot lines (high contrast)
fig2, ax2 = plt.subplots(figsize=(14,6))

# Background colors
fig2.patch.set_facecolor('black')
ax2.set_facecolor('black')

# Plot lines (high contrast)
ax2.plot(
    month_1['tpep_pickup_datetime'],
    month_1['Trips'],
    label='Actual Trips',
    color='blue',
    linewidth=2
)

ax2.plot(
    month_1['tpep_pickup_datetime'],
    month_1['Fitted Values Sarimax'],
    label='SARIMAX Fitted',
    color='yellow',
    linestyle='--',
    linewidth=2
)
# Labels & title
ax2.set_xlabel('Datetime', color='white',fontsize=15)
ax2.set_ylabel('Trips', color='white',fontsize=15)
ax2.set_title('SARIMAX Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax2.tick_params(colors='white')

# Grid (optional but recommended)
ax2.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax2.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig2)

x_mae=mean_absolute_error(data_exogenous['Trips'],data_exogenous['Fitted Values Sarimax'])
x_mse = mean_squared_error(data_exogenous['Trips'],data_exogenous['Fitted Values Sarimax'])
x_rmse = root_mean_squared_error(data_exogenous['Trips'],data_exogenous['Fitted Values Sarimax'])

st.markdown(
    "<h3 style='text-align: center;'>Model Metrics</h3>",
    unsafe_allow_html=True
)
col1, col2, col3 = st.columns(3)

col1.metric("MAE", f"{x_mae:.2f}")
col2.metric("MSE", f"{x_mse:.2f}")
col3.metric("RMSE", f"{x_rmse:.2f}")

st.subheader("Impact of Exogenous Features")

st.markdown("""
After incorporating exogenous variables, the forecasting accuracy showed **only marginal improvement** compared to the SARIMAX model without external inputs.

This suggests that:
- Taxi demand is primarily driven by **strong temporal patterns** (hourly and daily seasonality)
- Weather and holiday effects may already be indirectly captured through historical demand
- Or their influence is **non-linear**, which SARIMAX may not fully capture
""")

st.subheader("XGBoost Model")

df =data_exogenous.copy()
##creating lags
df['lag_1'] = df['Trips'].shift(1)
df['lag_24'] = df['Trips'].shift(24)
df['lag_168'] = df['Trips'].shift(168)  # weekly
df['rolling_mean_24'] = df['Trips'].rolling(24).mean()
df['rolling_std_24'] = df['Trips'].rolling(24).std()

df['hour'] = df['tpep_pickup_datetime'].dt.hour
df['dayofweek'] = df['tpep_pickup_datetime'].dt.dayofweek
df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)

df = df.dropna()
df.set_index('tpep_pickup_datetime',inplace=True)

target = 'Trips'
features = [
    'lag_1', 'lag_24', 'lag_168',
    'rolling_mean_24', 'rolling_std_24',
    'hour', 'dayofweek', 'is_weekend',
    'temp', 'prcp', 'wspd',
    'is_holiday', 'is_festive_window'
]

X = df[features]
y = df[target]

split_date = pd.to_datetime('2025-09-01')  # Mid-year split for 2025-only data

mask_train = X.index < split_date
mask_test = X.index >= split_date

X_train = X[mask_train].copy()
X_test = X[mask_test].copy()
y_train = y[mask_train].copy()
y_test = y[mask_test].copy()


from xgboost import XGBRegressor

xgb_model = XGBRegressor(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    objective='reg:squarederror',
    random_state=42
)

xgb_model.fit(X_train, y_train)

y_pred = xgb_model.predict(X_test)

y_pred_series = pd.Series(
    y_pred,
    index=y_test.index,
    name="XGBoost_Predicted"
)
y_pred = y_pred.ravel()
y_pred = pd.Series(
    y_pred,
    index=y_test.index,
    name="Predicted")
y_pred =pd.DataFrame(y_pred,columns=['Predicted'])
results_df = pd.concat([y_test, y_pred], axis=1)

fig4, ax4 = plt.subplots(figsize=(14,6))

# Dark background (optional ‚Äì remove if you want default)
fig4.patch.set_facecolor('black')
ax4.set_facecolor('black')

ax4.plot(
    results_df.index,
    results_df['Trips'],
    label="Actual Trips",
    color="cyan",
    linewidth=2
)

ax4.plot(
    results_df.index,
    results_df['Predicted'],
    label="XGBoost Predicted",
    color="orange",
    linestyle="--",
    linewidth=2
)

ax4.set_title("XGBoost: Actual vs Predicted Trips", color="white", fontsize=14)
ax4.set_xlabel("Time", color="white")
ax4.set_ylabel("Trips", color="white")

ax4.tick_params(colors="white")
ax4.legend(facecolor="black", labelcolor="white")
ax4.grid(alpha=0.3)

st.pyplot(fig4)
xgb_mae = mean_absolute_error(y_test, y_pred)
xgb_mse = mean_squared_error(y_test, y_pred)
xgb_rmse = np.sqrt(mse)

print(f"XGBoost_MAE {xgb_mae:.2f}")
print(f"XGBoost_MSE {xgb_mse:.2f}")
print(f"XGBoost_RMSE {xgb_rmse:.2f}")

st.markdown(
    "<h3 style='text-align: center;'>Model Metrics</h3>",
    unsafe_allow_html=True
)
col1, col2, col3 = st.columns(3)

col1.metric("MAE", f"{xgb_mae:.2f}")
col2.metric("MSE", f"{xgb_mse:.2f}")
col3.metric("RMSE", f"{xgb_rmse:.2f}")
            
st.subheader("Final Model Conclusion")

results = pd.DataFrame({
    "Model": ["SARIMA-X", "SARIMA", "Prophet", "XGBoost"],
    "MAE":   [54.50, 50.64, 107.80, 34.79],
    "MSE":   [6088.55, 4997.24, 19341.38, 2282.12],
    "RMSE":  [78.03, 70.69, 139.07, 50.59]
}).set_index("Model")

st.subheader("üìä Model Performance Comparison")

st.dataframe(
    results.style
        .highlight_min(axis=0, color="lightgreen")
        .format("{:.2f}"),
    use_container_width=True
)

best_model = results["RMSE"].idxmin()

st.markdown(f"### üèÜ Best Performing Model: **{best_model}**")

cols = st.columns(len(results))

for col, (model, row) in zip(cols, results.iterrows()):
    with col:
        st.markdown(f"#### {model}")
        st.metric("MAE", f"{row['MAE']:.2f}")
        st.metric("RMSE", f"{row['RMSE']:.2f}")


st.markdown("""
### üìå Interpretation

- **XGBoost** achieves the lowest MAE and RMSE, indicating superior short-term and overall prediction accuracy.
- **SARIMA / SARIMAX** perform well in capturing temporal structure but are limited in handling complex nonlinear effects.
- **Prophet** shows the weakest performance for this dataset, likely due to limited sensitivity to short-term demand variability.
""")
st.success(
    "‚úÖ Conclusion: XGBoost outperforms traditional time-series models by effectively leveraging exogenous features and nonlinear relationships."
)

