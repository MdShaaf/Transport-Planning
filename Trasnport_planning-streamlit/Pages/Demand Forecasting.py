import pandas as pd
import streamlit as st
import duckdb
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import json
import os
import time
from prophet import Prophet
import pickle
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,root_mean_squared_error
from pmdarima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX
from meteostat import Point, Hourly
import holidays
from xgboost import XGBRegressor
import numpy as np

st.title("üöó Demand Forecasting")
@st.cache_data
def load_data():
    con = duckdb.connect(database=':memory:', read_only=False)
    path=r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\Sampled_Data\combined_sampled_data.parquet"
    df = con.execute(f"SELECT * FROM '{path}'").df()
    return df
data = load_data()

#filling null values
data['passenger_count'].fillna(0, inplace=True)
data['RatecodeID'].fillna(-1, inplace=True)
data['store_and_fwd_flag'].fillna('N', inplace=True)
data['congestion_surcharge'].fillna(0, inplace=True)
data['Airport_fee'].fillna(0, inplace=True)

data=data[data['total_amount']>0]
data=data[data['trip_distance']<=100]
data['Date']=data['tpep_pickup_datetime'].dt.date
data['Hour']=data['tpep_pickup_datetime'].dt.hour
data['Date']=pd.to_datetime(data['Date'])
data=data[(data['Date'].dt.year)==2025]

resampling = data.groupby(['Date','Hour']).size().reset_index()
resampling =resampling.rename(columns={0:'Trips'})
resampling['Date & Time']=(resampling['Date']+pd.to_timedelta(resampling['Hour'],unit='h'))
resampling['naive_forecast'] = resampling['Trips'].shift(24)
resampling.dropna(inplace=True)
january = resampling[resampling['Date'].dt.month==1]


st.subheader("1. Naive Forecasting Model")
st.markdown("""
A naive forecasting model is a simple time series forecasting method that uses the most recent observed value as the forecast for the next period. In this case, we are using the value from 24 hours ago (the same hour on the previous day) as the forecast for the current hour. This approach assumes that there is a daily pattern in the data, which is common in many time series datasets, especially those related to human activities such as transportation demand.
""")
fig0, ax0 = plt.subplots(figsize=(14,6))
fig0.patch.set_facecolor('black')
ax0.set_facecolor('black')

ax0.plot(
    january['Date & Time'],
    january['Trips'],
    label='Actual Trips',
    color='blue',
    linewidth=2
)
ax0.plot(
    january['Date & Time'],
    january['naive_forecast'],
    label='Naive Forecast',
    color='orange',
    linestyle='--',
    linewidth=2
)

# Labels & title
ax0.set_xlabel('Datetime', color='white',fontsize=15)
ax0.set_ylabel('Trips', color='white',fontsize=15)
ax0.set_title('Naive Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax0.tick_params(colors='white')

# Grid (optional but recommended)
ax0.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax0.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig0)
st.markdown("""
In the plot above, the blue line represents the actual number of trips recorded each hour in January 2025, while the orange line represents the forecasts generated by the naive model. As we can see, the naive forecast captures the general daily patterns in the data, but there are discrepancies between the actual trips and the forecasted values, especially during peak hours. This indicates that while the naive model is a good starting point, more sophisticated models may be needed to improve forecasting accuracy.
""")
st.markdown(
    "<h3 style='text-align: center;'>Performance Metrics</h3>",
    unsafe_allow_html=True
)

resampling['absolute_error'] = abs(resampling['Trips'] - resampling['naive_forecast'])
mae = mean_absolute_error(resampling['Trips'], resampling['naive_forecast'])
mse = mean_squared_error(resampling['Trips'], resampling['naive_forecast'])
rmse = root_mean_squared_error(resampling['Trips'], resampling['naive_forecast'])
# r2  = r2_score(resampling['Trips'], resampling['naive_forecast'])
col1, col2, col3 = st.columns(3)

col1.metric("MAE", f"{mae:.2f}")
col2.metric("MSE", f"{mse:.2f}")
col3.metric("RMSE", f"{rmse:.2f}")
# col4.metric("R2_Score",f"{r2:.2f}")

st.subheader("2. SARIMA Model")

st.markdown("""
SARIMA effectively models recurring travel demand patterns such as weekday‚Äìweekend variation and peak periods.
This allows the model to significantly reduce both average forecast error (MAE) and large deviations (RMSE), making it suitable for transport demand forecasting applications.
            """)
resampling_data_for_sarimax = resampling.set_index('Date & Time')

MODEL_PATH = r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\Trasnport_planning-streamlit\models/sarimax_model.pkl"
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
status = st.empty()

if os.path.exists(MODEL_PATH):
    status.success("‚úÖ Loading the saved model...")
    
    with open(MODEL_PATH, "rb") as f:
        sarimax_results = pickle.load(f)

    time.sleep(3)   # optional: let user see it
    status.empty()

else:
    status.info("‚è≥ Creating the SARIMA model (first run)...")

    # Based on AUTO-ARIMA Model
    order_best = (2, 0, 0)
    seasonal_order_best = (1, 0, 1, 24)

    sarimax_model = SARIMAX(
        resampling_data_for_sarimax['Trips'],
        order=order_best,
        seasonal_order=seasonal_order_best,
        enforce_stationarity=False,
        enforce_invertibility=False
    )

    sarimax_results = sarimax_model.fit(disp=False)

    with open(MODEL_PATH, "wb") as f:
        pickle.dump(sarimax_results, f)

    status.success("‚úÖ SARIMA model trained and saved")
    time.sleep(2)
    status.empty()

#assign a column to predicted values
resampling_data_for_sarimax['Fitted'] = sarimax_results.fittedvalues

#calculating the errors
resampling_data_for_sarimax['abs_error'] = abs(resampling_data_for_sarimax['Trips'] - resampling_data_for_sarimax['Fitted'])

sarimax_january = resampling_data_for_sarimax[resampling_data_for_sarimax.index.month==1]

fig, ax = plt.subplots(figsize=(14,6))

# Background colors
fig.patch.set_facecolor('black')
ax.set_facecolor('black')

# Plot lines (high contrast)
ax.plot(
    sarimax_january.index,
    sarimax_january['Trips'],
    label='Actual Trips',
    color='cyan',
    linewidth=2
)

ax.plot(
    sarimax_january.index,
    sarimax_january['Fitted'],
    label='SARIMA Fitted',
    color='orange',
    linestyle='--',
    linewidth=2
)

# Labels & title
ax.set_xlabel('Datetime', color='white',fontsize=15)
ax.set_ylabel('Trips', color='white',fontsize=15)
ax.set_title('SARIMA Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax.tick_params(colors='white')

# Grid (optional but recommended)
ax.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig)

#acuracy comaprision
mae_sarimax =mean_absolute_error(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])
mse_sarimax =mean_squared_error(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])
rmse_sarimax =root_mean_squared_error(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])
# r1_sarima = r2_score(resampling_data_for_sarimax['Trips'], resampling_data_for_sarimax['Fitted'])

st.markdown(
    "<h3 style='text-align: center;'>Model Comparison: Baseline vs SARIMA</h3>",
    unsafe_allow_html=True
)

col1, col2, col3 = st.columns(3)

col1.metric(
    label="MAE",
    value=f"{mae_sarimax:.2f}",
    delta="51% lower than baseline"
)

col2.metric(
    label="MSE",
    value=f"{mse_sarimax:.2f}",
    delta="80% lower than baseline"
)

col3.metric(
    label="RMSE",
    value=f"{rmse_sarimax:.2f}",
    delta="56% lower than baseline"
)


####Prophet Model 

st.subheader("3. Prophet Model")

prophet_data = (resampling_data_for_sarimax.reset_index())
prophet_data = prophet_data[['Date & Time','Trips']]
prophet_data=prophet_data.rename(columns={'Date & Time':'ds','Trips':'y'})

prophet_model_path = r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\models\prophet_model.pkl"
os.makedirs(os.path.dirname(prophet_model_path), exist_ok=True)
status = st.empty()

if os.path.exists(prophet_model_path):
    status.success("‚úÖ Loading the saved model...")
    
    with open(prophet_model_path, "rb") as f:
        prophet_model = pickle.load(f)

    time.sleep(3)   # optional: let user see it
    status.empty()

else:
    status.info("‚è≥ Error:Prophet Model doesn't exists please create and run again!!)...")

    time.sleep(2)
    status.empty()

future = prophet_model.make_future_dataframe(periods=0,freq='H')
prophet_forecast = prophet_model.predict(future)
df_compare = resampling_data_for_sarimax.copy()
df_compare['prophet_fitted'] = prophet_forecast['yhat'].values
df_compare['sarimax_fitted'] = sarimax_results.fittedvalues

#Let's compare the results
data_comaparision = df_compare[df_compare['Date'].dt.month==1]

plt.figure(figsize=(12,8))
plt.plot(data_comaparision.index,data_comaparision['Trips'],color='red')
plt.plot(data_comaparision.index,data_comaparision['prophet_fitted'],color='orange')
plt.plot(data_comaparision.index,data_comaparision['sarimax_fitted'],color='blue')
plt.show()

fig1, ax1 = plt.subplots(figsize=(14,6))

# Background colors
fig1.patch.set_facecolor('black')
ax1.set_facecolor('black')

# Plot lines (high contrast)
ax1.plot(
    data_comaparision.index,
    data_comaparision['Trips'],
    label='Actual Trips',
    color='blue',
    linewidth=2
)

# ax1.plot(
#     data_comaparision.index,
#     data_comaparision['sarimax_fitted'],
#     label='SARIMAX Fitted',
#     color='orange',
#     linestyle='--',
#     linewidth=2
# )

ax1.plot(
    data_comaparision.index,
    data_comaparision['prophet_fitted'],
    label='Prophet Fitted',
    color='red',
    linestyle='--',
    linewidth=2
)
# Labels & title
ax1.set_xlabel('Datetime', color='white',fontsize=15)
ax1.set_ylabel('Trips', color='white',fontsize=15)
ax1.set_title('SARIMAX Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax1.tick_params(colors='white')

# Grid (optional but recommended)
ax1.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax1.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig1)

st.markdown(
    "<h3 style='text-align: center;'>Performance Metrics</h3>",
    unsafe_allow_html=True
)


mae_prophet = mean_absolute_error(df_compare['Trips'], df_compare['prophet_fitted'])
mse_prophet = mean_squared_error(df_compare['Trips'], df_compare['prophet_fitted'])
rmse_prophet = np.sqrt(mse_prophet)

col1, col2, col3 = st.columns(3)

col1.metric(
    label="MAE",
    value=f"{mae_prophet:.2f}"
)
col2.metric(
    label="MSE",
    value=f"{mse_prophet:.2f}"
)

col3.metric(
    label="RMSE",
    value=f"{rmse_prophet:.2f}"

)

st.markdown(
    "<h3 style='text-align: center;'>Model Comparison: Prophet vs SARIMA</h3>",
    unsafe_allow_html=True
)

st.markdown("""
**Conclusion:**  
SARIMA outperforms Prophet across all evaluation metrics, reducing average and peak forecasting errors by nearly half. 
This makes SARIMA more suitable for operational transport demand forecasting.
""")

#Let's build some lag Features to try if SARIMAX imporvess
#Fetching Weather Data for NYC
st.subheader("Why Add Exogenous Features?")
st.markdown("""
Exogenous features such as **weather conditions** (temperature, rainfall, wind speed) and **calendar effects** (holidays and festive windows) were added to capture external factors that may influence taxi demand.

Although SARIMAX can model trends and seasonality using historical demand alone, real-world travel patterns are often affected by **non-temporal factors** such as bad weather or public holidays.  
Including these variables allows the model to test whether such external signals provide additional predictive power.
""")
#To avoid streamlit load time the exogenous features where added in a separate file and loaded the resampled data directly
@st.cache_data
def load_exogenous_data():
    path=r"C:\Users\Shaaf\Desktop\Data Science\Practice Projects\Transport Planning\Sampled_Data/sarimax_exogenous_Data_with_resample.csv"
    df = pd.read_csv(path)
    return df
data_exogenous = load_exogenous_data()
data_exogenous.reset_index(drop=True,inplace=True)
data_exogenous['tpep_pickup_datetime'] =pd.to_datetime(data_exogenous['tpep_pickup_datetime'])
month_1 = data_exogenous[data_exogenous['tpep_pickup_datetime'].dt.month==1]

fig2, ax2 = plt.subplots(figsize=(14,6))

# Background colors
# Plot lines (high contrast)
fig2, ax2 = plt.subplots(figsize=(14,6))

# Background colors
fig2.patch.set_facecolor('black')
ax2.set_facecolor('black')

# Plot lines (high contrast)
ax2.plot(
    month_1['tpep_pickup_datetime'],
    month_1['Trips'],
    label='Actual Trips',
    color='blue',
    linewidth=2
)

ax2.plot(
    month_1['tpep_pickup_datetime'],
    month_1['Fitted Values Sarimax'],
    label='SARIMAX Fitted',
    color='yellow',
    linestyle='--',
    linewidth=2
)
# Labels & title
ax2.set_xlabel('Datetime', color='white',fontsize=15)
ax2.set_ylabel('Trips', color='white',fontsize=15)
ax2.set_title('SARIMAX Model Fitting ‚Äì January 2025', color='white', fontsize=20)

# Ticks
ax2.tick_params(colors='white')

# Grid (optional but recommended)
ax2.grid(color='gray', linestyle='--', alpha=0.3)

# Legend
ax2.legend(facecolor='black', labelcolor='white')

# ‚úÖ Streamlit display
st.pyplot(fig2)

x_mae=mean_absolute_error(data_exogenous['Trips'],data_exogenous['Fitted Values Sarimax'])
x_mse = mean_squared_error(data_exogenous['Trips'],data_exogenous['Fitted Values Sarimax'])
x_rmse = root_mean_squared_error(data_exogenous['Trips'],data_exogenous['Fitted Values Sarimax'])

st.markdown(
    "<h3 style='text-align: center;'>Model Metrics</h3>",
    unsafe_allow_html=True
)
col1, col2, col3 = st.columns(3)

col1.metric("MAE", f"{x_mae:.2f}")
col2.metric("MSE", f"{x_mse:.2f}")
col3.metric("RMSE", f"{x_rmse:.2f}")

st.subheader("Impact of Exogenous Features")

st.markdown("""
After incorporating exogenous variables, the forecasting accuracy showed **only marginal improvement** compared to the SARIMAX model without external inputs.

This suggests that:
- Taxi demand is primarily driven by **strong temporal patterns** (hourly and daily seasonality)
- Weather and holiday effects may already be indirectly captured through historical demand
- Or their influence is **non-linear**, which SARIMAX may not fully capture
""")

st.subheader("XGBoost Model")

df =data_exogenous.copy()
##creating lags
df['lag_1'] = df['Trips'].shift(1)
df['lag_24'] = df['Trips'].shift(24)
df['lag_168'] = df['Trips'].shift(168)  # weekly
df['rolling_mean_24'] = df['Trips'].rolling(24).mean()
df['rolling_std_24'] = df['Trips'].rolling(24).std()

df['hour'] = df['tpep_pickup_datetime'].dt.hour
df['dayofweek'] = df['tpep_pickup_datetime'].dt.dayofweek
df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)

df = df.dropna()
df.set_index('tpep_pickup_datetime',inplace=True)

target = 'Trips'
features = [
    'lag_1', 'lag_24', 'lag_168',
    'rolling_mean_24', 'rolling_std_24',
    'hour', 'dayofweek', 'is_weekend',
    'temp', 'prcp', 'wspd',
    'is_holiday', 'is_festive_window'
]

X = df[features]
y = df[target]

split_date = pd.to_datetime('2025-09-01')  # Mid-year split for 2025-only data

mask_train = X.index < split_date
mask_test = X.index >= split_date

X_train = X[mask_train].copy()
X_test = X[mask_test].copy()
y_train = y[mask_train].copy()
y_test = y[mask_test].copy()


from xgboost import XGBRegressor

xgb_model = XGBRegressor(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    objective='reg:squarederror',
    random_state=42
)

xgb_model.fit(X_train, y_train)

y_pred = xgb_model.predict(X_test)

y_pred_series = pd.Series(
    y_pred,
    index=y_test.index,
    name="XGBoost_Predicted"
)
y_pred = y_pred.ravel()
y_pred = pd.Series(
    y_pred,
    index=y_test.index,
    name="Predicted")
y_pred =pd.DataFrame(y_pred,columns=['Predicted'])
results_df = pd.concat([y_test, y_pred], axis=1)

fig4, ax4 = plt.subplots(figsize=(14,6))

# Dark background (optional ‚Äì remove if you want default)
fig4.patch.set_facecolor('black')
ax4.set_facecolor('black')

ax4.plot(
    results_df.index,
    results_df['Trips'],
    label="Actual Trips",
    color="cyan",
    linewidth=2
)

ax4.plot(
    results_df.index,
    results_df['Predicted'],
    label="XGBoost Predicted",
    color="orange",
    linestyle="--",
    linewidth=2
)

ax4.set_title("XGBoost: Actual vs Predicted Trips", color="white", fontsize=14)
ax4.set_xlabel("Time", color="white")
ax4.set_ylabel("Trips", color="white")

ax4.tick_params(colors="white")
ax4.legend(facecolor="black", labelcolor="white")
ax4.grid(alpha=0.3)

st.pyplot(fig4)
xgb_mae = mean_absolute_error(y_test, y_pred)
xgb_mse = mean_squared_error(y_test, y_pred)
xgb_rmse = np.sqrt(mse)

print(f"XGBoost_MAE {xgb_mae:.2f}")
print(f"XGBoost_MSE {xgb_mse:.2f}")
print(f"XGBoost_RMSE {xgb_rmse:.2f}")

st.markdown(
    "<h3 style='text-align: center;'>Model Metrics</h3>",
    unsafe_allow_html=True
)
col1, col2, col3 = st.columns(3)

col1.metric("MAE", f"{xgb_mae:.2f}")
col2.metric("MSE", f"{xgb_mse:.2f}")
col3.metric("RMSE", f"{xgb_rmse:.2f}")
            
st.subheader("Final Model Conclusion")

results = pd.DataFrame({
    "Model": ["SARIMA-X", "SARIMA", "Prophet", "XGBoost"],
    "MAE":   [54.50, 50.64, 107.80, 34.79],
    "MSE":   [6088.55, 4997.24, 19341.38, 2282.12],
    "RMSE":  [78.03, 70.69, 139.07, 50.59]
}).set_index("Model")

st.subheader("üìä Model Performance Comparison")

st.dataframe(
    results.style
        .highlight_min(axis=0, color="lightgreen")
        .format("{:.2f}"),
    use_container_width=True
)

best_model = results["RMSE"].idxmin()

st.markdown(f"### üèÜ Best Performing Model: **{best_model}**")

cols = st.columns(len(results))

for col, (model, row) in zip(cols, results.iterrows()):
    with col:
        st.markdown(f"#### {model}")
        st.metric("MAE", f"{row['MAE']:.2f}")
        st.metric("RMSE", f"{row['RMSE']:.2f}")


st.markdown(
    "<h3 style='font-size:24px;'>Residual Analysis</h3>",
    unsafe_allow_html=True
)
residual_df = results_df.copy()
residual_df['Residual']=residual_df['Trips']-residual_df['Predicted']
fig5, ax5 = plt.subplots(figsize=(14,5))

ax5.plot(residual_df.index, residual_df["Residual"], color="orange", linewidth=1)
ax5.axhline(0, color="white", linestyle="--", linewidth=1)

fig5.patch.set_facecolor("black")
ax5.set_facecolor("black")

ax5.set_title("Residuals Over Time (XGBoost)", color="white")
ax5.set_ylabel("Residual (Actual ‚àí Predicted)", color="white")
ax5.set_xlabel("Datetime", color="white")
ax5.tick_params(colors="white")

st.pyplot(fig5)
st.markdown("Residuals fluctuate around zero with no strong trend, indicating that the XGBoost model does not exhibit systematic bias over time.")


##Residual Histogram
fig6, ax6 = plt.subplots(figsize=(8,5))

ax6.hist(residual_df["Residual"], bins=50, color="cyan", edgecolor="black")

fig6.patch.set_facecolor("black")
ax6.set_facecolor("black")

ax6.set_title("Distribution of Residuals", color="white")
ax6.set_xlabel("Residual Value", color="white")
ax6.set_ylabel("Frequency", color="white")
ax6.tick_params(colors="white")
st.pyplot(fig6)

st.markdown("Residuals are approximately centered around zero, indicating unbiased predictions with occasional large deviations during peak demand periods.")


fig7, ax7 = plt.subplots(figsize=(8,5))

ax7.scatter(
    residual_df["Predicted"],
    residual_df["Residual"],
    alpha=0.4,
    color="lime"
)

ax7.axhline(0, color="white", linestyle="--")

fig7.patch.set_facecolor("black")
ax7.set_facecolor("black")

ax7.set_title("Residuals vs Predicted Values", color="white")
ax7.set_xlabel("Predicted Trips", color="white")
ax7.set_ylabel("Residual", color="white")
ax7.tick_params(colors="white")
st.pyplot(fig7)
st.markdown("Residual spread increases slightly at higher predicted demand, suggesting higher uncertainty during peak hours.")




residual_df["Hour"] = residual_df.index.hour

hourly_residuals = residual_df.groupby("Hour")["Residual"].mean()

fig8, ax8 = plt.subplots(figsize=(10,5))

ax8.plot(hourly_residuals.index, hourly_residuals.values, marker="o", color="orange")

fig8.patch.set_facecolor("black")
ax8.set_facecolor("black")

ax8.set_title("Average Residual by Hour of Day", color="white")
ax8.set_xlabel("Hour", color="white")
ax8.set_ylabel("Mean Residual", color="white")
ax8.tick_params(colors="white")

st.pyplot(fig8)
st.markdown("The model slightly underpredicts demand during peak commuting hours, which is expected due to sudden demand spikes.")

###let's plot Important features
importance = xgb_model.feature_importances_
feature_importance_df = pd.DataFrame({
    "Feature": X_train.columns,
    "Importance": importance
}).sort_values(by="Importance", ascending=False)
fig9, ax9 = plt.subplots(figsize=(8,5))
fig9.patch.set_facecolor('black')
ax9.set_facecolor('black')

ax9.barh(
    feature_importance_df["Feature"].head(10)[::-1],
    feature_importance_df["Importance"].head(10)[::-1],
    color='cyan'
)

ax9.set_xlabel("Importance", color='white')
ax9.set_title("Top XGBoost Feature Importances", color='white')
ax9.tick_params(colors='white')

st.pyplot(fig9)

st.markdown("""
The XGBoost model automatically learns which factors contribute most to predicting taxi demand.
Feature importance scores represent the **relative contribution** of each variable to the final prediction.
""")

st.subheader("Final Conclusion")

st.markdown("""
### üèÜ Best Performing Model: **XGBoost**

**Key Findings:**
- XGBoost achieved the **lowest MAE (34.79)** and **lowest RMSE (50.59)** among all tested models.
- SARIMA and SARIMAX captured temporal patterns well but struggled with **non-linear effects**.
- Prophet underperformed due to its assumption of smoother trend‚Äìseasonality structures.
- Adding exogenous features (weather, holidays, festive windows) showed **limited improvement** for SARIMAX.
- XGBoost effectively leveraged **lag features, calendar effects, and weather variables** together.

**Final Decision:**
- XGBoost is selected as the **final production model** due to superior accuracy, robustness, and flexibility.
""")


st.success(
    "‚úÖ Conclusion: XGBoost outperforms traditional time-series models by effectively leveraging exogenous features and nonlinear relationships."
)

